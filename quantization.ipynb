{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.28s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import pyvww\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "training_set = pyvww.pytorch.VisualWakeWordsClassification(\n",
    "    root=\"./visualwakewords/path-to-COCO-dataset/train2014\",\n",
    "    annFile=\"./visualwakewords/new-path-to-visualwakewords-dataset/annotations/instances_train.json\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "validation_set = pyvww.pytorch.VisualWakeWordsClassification(\n",
    "    root=\"./visualwakewords/path-to-COCO-dataset/train2014\",\n",
    "    annFile=\"./visualwakewords/new-path-to-visualwakewords-dataset/annotations/instances_val.json\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Training Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def ptdq(model, weights, save_path):\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    device_cpu = torch.device('cpu')\n",
    "\n",
    "    state_dict = torch.load(weights, map_location=torch.device('cuda'))\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    model_dynamic_quantized = torch.quantization.quantize_dynamic(\n",
    "        model, \n",
    "        qconfig_spec={torch.nn.Linear, torch.nn.LSTM, torch.nn.GRU, torch.nn.RNN}, \n",
    "        dtype=torch.qint8\n",
    "    )\n",
    "\n",
    "    torch.save(model_dynamic_quantized, save_path)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Model loaded successfully\")\n",
    "\n",
    "    val_correct=0\n",
    "    for batch_idx, (vinputs, vlabels) in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "        voutputs = model(vinputs)\n",
    "\n",
    "        _, vpreds = torch.max(voutputs, 1)\n",
    "        val_correct += (vpreds == vlabels).sum().item()\n",
    "        \n",
    "    print(f'Non Quantized Model Accuracy: {val_correct/(64*len(validation_loader))}')\n",
    "\n",
    "    model_dynamic_quantized.eval()\n",
    "\n",
    "    val_correct = 0\n",
    "    for batch_idx, (vinputs, vlabels) in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vinputs.to(device_cpu), vlabels.to(device_cpu)  # Move to CPU\n",
    "        voutputs = model_dynamic_quantized(vinputs)\n",
    "        _, vpreds = torch.max(voutputs, 1)\n",
    "        val_correct += (vpreds == vlabels).sum().item()\n",
    "\n",
    "        \n",
    "    print(f'Quantized Model Accuracy: {val_correct/(64*len(validation_loader))}')\n",
    "    \n",
    "    torch.save(model, './dummy.ph')\n",
    "    # Compare model sizes\n",
    "    original_size = os.path.getsize('./dummy.ph') / (1024 * 1024)  # Convert bytes to MB\n",
    "    quantized_size = os.path.getsize(save_path) / (1024 * 1024)  # Convert bytes to MB\n",
    "    os.remove('./dummy.ph')\n",
    "    print(f'Original Model Size: {original_size:.2fhttps://github.com/ManosXen/embedded_computer_vision.git} MB')\n",
    "    print(f'Quantized Model Size: {quantized_size:.2f} MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shufflenet x0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Non Quantized Model Accuracy: 0.8204365079365079\n",
      "Quantized Model Accuracy: 0.8198164682539683\n",
      "Original Model Size: 1.47 MB\n",
      "Quantized Model Size: 1.48 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.shufflenet_v2_x0_5(weights=None)\n",
    "model.fc = torch.nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    "\n",
    "ptdq(model, \"./models/full_models/shufflenet_v2_x0_5.pth\", \"./models/quantized_models/dynamic/shufflenet_v2_x0_5.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shufflenet x1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Non Quantized Model Accuracy: 0.8420138888888888\n",
      "Quantized Model Accuracy: 0.8421378968253969\n",
      "Original Model Size: 4.98 MB\n",
      "Quantized Model Size: 4.98 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as modelshttps://github.com/ManosXen/embedded_computer_vision.git\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "model = models.shufflenet_v2_x1_0(weights=None)\n",
    "model.fc = torch.nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    "\n",
    "ptdq(model, \"./models/full_models/shufflenet_v2_x1_0.pth\", \"./models/quantized_models/dynamic/shufflenet_v2_x1_0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SqueezeNet 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δεν υποστηρίζει όλα τα layers πέρα από:\n",
    "* torch.nn.Linear\n",
    "* torch.nn.LSTM\n",
    "* torch.nn.GRU\n",
    "* torch.nn.RNN (limited)\n",
    "\n",
    "οπότε δεν κάνει quantization για το squeezenet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για το dynamic quantization οι επιλογές για dtype είναι qint8, quint8, qint32, float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Training Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "subset_indices = list(range(150))\n",
    "subset = Subset(training_loader.dataset, subset_indices)\n",
    "observation_loader = torch.utils.data.DataLoader(subset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def ptsq(model, weights, save_path):\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    device_cpu = torch.device('cpu')\n",
    "\n",
    "    backend = \"fbgemm\" #x86\n",
    "\n",
    "    state_dict = torch.load(weights, map_location=torch.device('cuda'))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    m = copy.deepcopy(model)\n",
    "\n",
    "    quantized_model = nn.Sequential(torch.quantization.QuantStub(), \n",
    "                  m, \n",
    "                  torch.quantization.DeQuantStub())\n",
    "\n",
    "    quantized_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "    torch.quantization.prepare(quantized_model, inplace=True)\n",
    "\n",
    "    for vinputs, vlabels in observation_loader:\n",
    "            vinputs, vlabels = vinputs.to(device_cpu), vlabels.to(device_cpu)  # Move to CPU\n",
    "            quantized_model(vinputs)\n",
    "    \n",
    "    torch.quantization.convert(quantized_model, inplace=True)\n",
    "    \n",
    "    torch.save(quantized_model.state_dict(), save_path)\n",
    "    torch.save(model.state_dict(), './dummy.pt')\n",
    "    # Compare model sizes\n",
    "    original_size = os.path.getsize('./dummy.pt') / (1024 * 1024)  # Convert bytes to MB\n",
    "    quantized_size = os.path.getsize(save_path) / (1024 * 1024)  # Convert bytes to MB\n",
    "    os.remove('./dummy.pt')\n",
    "    print(f'Original Model Size: {original_size:.2f} MB')\n",
    "    print(f'Quantized Model Size: {quantized_size:.2f} MB')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    val_correct=0\n",
    "    start_time=time.time()\n",
    "    for batch_idx, (vinputs, vlabels) in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "        voutputs = model(vinputs)\n",
    "\n",
    "        _, vpreds = torch.max(voutputs, 1)\n",
    "        val_correct += (vpreds == vlabels).sum().item()\n",
    "    end_time=time.time()\n",
    "    execution_time=end_time-start_time    \n",
    "    print(f'Non Quantized Model Accuracy: {val_correct/(64*len(validation_loader)):.3f}')\n",
    "    print(f'Execution Time of Non Quantized Models when running on GPU {execution_time:.3f} sec')\n",
    "    print(f'FPS Non Quantized on GPU: {(64*len(validation_loader)/execution_time):.3f}')\n",
    "\n",
    "    torch.quantization.convert(quantized_model, inplace=True)\n",
    "    quantized_model.eval()\n",
    "\n",
    "    val_correct = 0\n",
    "    start_time=time.time()\n",
    "    for batch_idx, (vinputs, vlabels) in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vinputs.to(device_cpu), vlabels.to(device_cpu)  # Move to CPU\n",
    "        voutputs = quantized_model(vinputs)\n",
    "        _, vpreds = torch.max(voutputs, 1)\n",
    "        val_correct += (vpreds == vlabels).sum().item()\n",
    "    end_time=time.time()\n",
    "    execution_time=end_time-start_time\n",
    "        \n",
    "    print(f'Quantized Model Accuracy: {val_correct/(64*len(validation_loader)):.3f}')\n",
    "    print(f'Execution Time of Quantized Model CPU {execution_time:.3f} sec')\n",
    "    print(f'FPS Quantized CPU: {(64*len(validation_loader))/execution_time:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleNet v2 x0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 1.43 MB\n",
      "Quantized Model Size: 0.65 MB\n",
      "Non Quantized Model Accuracy: 0.820\n",
      "Execution Time of Non Quantized Models when running on GPU 17.458 sec\n",
      "FPS Non Quantized on GPU: 461.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manos-xenos/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/shufflenetv2.py:97: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:168.)\n",
      "  out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)\n",
      "/home/manos-xenos/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/shufflenetv2.py:95: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:168.)\n",
      "  out = torch.cat((x1, self.branch2(x2)), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Accuracy: 0.806\n",
      "Execution Time of Quantized Model CPU 29.871 sec\n",
      "FPS Quantized CPU: 269.960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.shufflenet_v2_x0_5(weights=None)\n",
    "model.fc = torch.nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    "\n",
    "ptsq(model, \"./models/full_models/shufflenet_v2_x0_5.pth\", \"./models/quantized_models/static/shufflenet_v2_x0_5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleNet v2 x1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 4.95 MB\n",
      "Quantized Model Size: 1.63 MB\n",
      "Non Quantized Model Accuracy: 0.842\n",
      "Execution Time of Non Quantized Models when running on GPU 18.185 sec\n",
      "FPS Non Quantized on GPU: 443.435\n",
      "Quantized Model Accuracy: 0.828\n",
      "Execution Time of Quantized Model CPU 198.493 sec\n",
      "FPS Quantized CPU: 40.626\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "model = models.shufflenet_v2_x1_0(weights=None)\n",
    "model.fc = torch.nn.Linear(in_features=1024, out_features=2, bias=True)\n",
    "\n",
    "ptsq(model, \"./models/full_models/shufflenet_v2_x1_0.pth\", \"./models/quantized_models/static/shufflenet_v2_x1_0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet 1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 2.77 MB\n",
      "Quantized Model Size: 0.79 MB\n",
      "Non Quantized Model Accuracy: 0.888\n",
      "Execution Time of Non Quantized Models when running on GPU 17.278 sec\n",
      "FPS Non Quantized on GPU: 466.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manos-xenos/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/squeezenet.py:31: UserWarning: All inputs of this cat operator must share the same quantization parameters. Otherwise large numerical inaccuracies may occur. (Triggered internally at /pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:168.)\n",
      "  return torch.cat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Accuracy: 0.854\n",
      "Execution Time of Quantized Model CPU 49.923 sec\n",
      "FPS Quantized CPU: 161.529\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "model = models.squeezenet1_1(weights=None)\n",
    "model.classifier[1] = torch.nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "ptsq(model, \"./models/full_models/squeezenet1_1.pth\", \"./models/quantized_models/static/squeezenet1_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 42.71 MB\n",
      "Quantized Model Size: 10.87 MB\n",
      "Non Quantized Model Accuracy: 0.894\n",
      "Execution Time of Non Quantized Models when running on GPU 18.583 sec\n",
      "FPS Non Quantized on GPU: 433.956\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::add.out' with arguments from the 'QuantizedCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::add.out' is only available for these backends: [CPU, CUDA, Meta, MkldnnCPU, SparseCPU, SparseCUDA, SparseMeta, SparseCsrCPU, SparseCsrCUDA, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:535 [kernel]\nSparseCPU: registered at /pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1407 [kernel]\nSparseCUDA: registered at /pytorch/build/aten/src/ATen/RegisterSparseCUDA.cpp:1577 [kernel]\nSparseMeta: registered at /pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:291 [kernel]\nSparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1155 [kernel]\nSparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrCUDA.cpp:1291 [kernel]\nSparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrMeta.cpp:1069 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:23301 [kernel]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4942 [kernel]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:17801 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mptsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/full_models/resnet18.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/quantized_models/static/resnet.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 62\u001b[0m, in \u001b[0;36mptsq\u001b[0;34m(model, weights, save_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (vinputs, vlabels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(validation_loader):\n\u001b[1;32m     61\u001b[0m     vinputs, vlabels \u001b[38;5;241m=\u001b[39m vinputs\u001b[38;5;241m.\u001b[39mto(device_cpu), vlabels\u001b[38;5;241m.\u001b[39mto(device_cpu)  \u001b[38;5;66;03m# Move to CPU\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     voutputs \u001b[38;5;241m=\u001b[39m \u001b[43mquantized_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvinputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     _, vpreds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(voutputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m     val_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (vpreds \u001b[38;5;241m==\u001b[39m vlabels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/resnet.py:102\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m--> 102\u001b[0m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midentity\u001b[49m\n\u001b[1;32m    103\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::add.out' with arguments from the 'QuantizedCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::add.out' is only available for these backends: [CPU, CUDA, Meta, MkldnnCPU, SparseCPU, SparseCUDA, SparseMeta, SparseCsrCPU, SparseCsrCUDA, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:535 [kernel]\nSparseCPU: registered at /pytorch/build/aten/src/ATen/RegisterSparseCPU.cpp:1407 [kernel]\nSparseCUDA: registered at /pytorch/build/aten/src/ATen/RegisterSparseCUDA.cpp:1577 [kernel]\nSparseMeta: registered at /pytorch/build/aten/src/ATen/RegisterSparseMeta.cpp:291 [kernel]\nSparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrCPU.cpp:1155 [kernel]\nSparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrCUDA.cpp:1291 [kernel]\nSparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterSparseCsrMeta.cpp:1069 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:23301 [kernel]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4942 [kernel]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:19365 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:17801 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "ptsq(model, \"./models/full_models/resnet18.pth\", \"./models/quantized_models/static/resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 5.95 MB\n",
      "Quantized Model Size: 1.86 MB\n",
      "Non-Quantized Model Accuracy: 0.8779\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m num_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39min_features  \u001b[38;5;66;03m# Get input features of last FC layer\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_features, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Change output to 2 classes\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mptsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/full_models/mobilenet_v3_Small_freeze.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/quantized_models/static/mobilenet_v3_Small_freeze.ph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 66\u001b[0m, in \u001b[0;36mptsq\u001b[0;34m(model, weights, save_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vinputs, vlabels \u001b[38;5;129;01min\u001b[39;00m validation_loader:\n\u001b[1;32m     65\u001b[0m     vinputs, vlabels \u001b[38;5;241m=\u001b[39m vinputs\u001b[38;5;241m.\u001b[39mto(device_cpu), vlabels\u001b[38;5;241m.\u001b[39mto(device_cpu)\n\u001b[0;32m---> 66\u001b[0m     voutputs \u001b[38;5;241m=\u001b[39m \u001b[43mquantized_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvinputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Output is quantized\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     voutputs \u001b[38;5;241m=\u001b[39m voutputs\u001b[38;5;241m.\u001b[39mdequantize()  \u001b[38;5;66;03m# Dequantize before torch.max\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     _, vpreds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(voutputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:220\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:210\u001b[0m, in \u001b[0;36mMobileNetV3._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:111\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    113\u001b[0m         result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Ενσωμετωμένα Συστήματα Επεξεργασίας/bonus_project/lib/python3.12/site-packages/torchvision/ops/misc.py:260\u001b[0m, in \u001b[0;36mSqueezeExcitation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    259\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: empty_strided not supported on quantized tensors yet see https://github.com/pytorch/pytorch/issues/74540"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "\n",
    "model = models.mobilenet_v3_small(weights=None)\n",
    "num_features = model.classifier[-1].in_features  # Get input features of last FC layer\n",
    "model.classifier[-1] = nn.Linear(num_features, 2)  # Change output to 2 classes\n",
    "\n",
    "ptsq(model, \"./models/full_models/mobilenet_v3_Small_freeze.pth\", \"./models/quantized_models/static/mobilenet_v3_Small_freeze.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "speedup_pc = [1.285, 0.579, 1.854]\n",
    "speedup_rasberry = [0.725, 0.581, 0.583]\n",
    "models = [\"ShuffleNet x0.5\", \"ShuffleNet x1.0\", \"Squeezenet 1.1\"]\n",
    "\n",
    "# Set up the bar positions\n",
    "x = np.arange(len(models))  # Creates positions [0, 1, 2]\n",
    "bar_width = 0.35  # Width of each bar\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))  # Set figure size\n",
    "plt.bar(x - bar_width/2, speedup_pc, bar_width, label='PC', color='skyblue')\n",
    "plt.bar(x + bar_width/2, speedup_rasberry, bar_width, label='Raspberry Pi', color='lightcoral')\n",
    "\n",
    "# Add a dashed line at speedup = 1\n",
    "plt.axhline(y=1, color='black', linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Speedup')\n",
    "plt.title('Speedup of Quantized vs Non-Quantized Models on PC and Raspberry Pi')\n",
    "plt.xticks(x, models)  # Set model names on x-axis\n",
    "plt.legend()  # Add a legend\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)  # Add a subtle grid\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()  # Adjust layout to fit everything nicely\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bonus_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
